{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\r\n",
    "from functions import *\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "from transformers import *\r\n",
    "from transformers.tokenization_utils import TextInputPair\r\n",
    "from sklearn.neural_network import MLPClassifier\r\n",
    "from copy import deepcopy\r\n",
    "import tensorflow as tf\r\n",
    "import pickle\r\n",
    "import scipy as sc\r\n",
    "import math as mt\r\n",
    "from joblib import dump, load\r\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT\r\n",
    "casing = \"bert-base-uncased\" \r\n",
    "tokenizer = BertTokenizer.from_pretrained(casing, do_lower_case=True, add_special_tokens=True)\r\n",
    "\r\n",
    "config = BertConfig(dropout=0.2, attention_dropout=0.2 ) #hidden_dropout_prob=0.2, attention_probs_dropout_prob=0.2\r\n",
    "config.output_hidden_states = False # if true outputs all layers\r\n",
    "\r\n",
    "model = TFBertModel.from_pretrained(casing, config = config)\r\n",
    "model.trainable = False\r\n",
    "emb_len = 768\r\n",
    "clear_output()\r\n",
    "\r\n",
    "# BERT\r\n",
    "n_cluster = 27 # Number of clusters to use\r\n",
    "n_pc = 12 # Number of main principal components to drop for local method\r\n",
    "n_pc_global = 15 # Number of main principal components to drop for global method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset glue (C:\\Users\\Beni\\.cache\\huggingface\\datasets\\glue\\cola\\1.0.0\\dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
      "100%|██████████| 3/3 [00:00<00:00, 999.12it/s]\n"
     ]
    }
   ],
   "source": [
    "ds = load_dataset('glue', 'cola')\r\n",
    "df = pd.concat([ds[\"train\"].to_pandas(), ds[\"validation\"].to_pandas(), ds[\"test\"].to_pandas()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stop_ix = ds[\"train\"].num_rows\r\n",
    "dev_stop_ix = ds[\"train\"].num_rows + ds[\"validation\"].num_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode (tokenize) all pairs of sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuple_list = df[\"sentence\"].to_list()\r\n",
    "encodings = tokenizer.batch_encode_plus(tuple_list, max_length=64, pad_to_max_length=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embarray = np.zeros((len(df), len(encodings[\"input_ids\"][0]), 768), dtype=np.float32)\r\n",
    "embarray = np.load(\"cola-bert-embs.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10515\n",
      "10530\n",
      "10545\n",
      "10560\n",
      "10575\n",
      "10590\n",
      "10605\n",
      "10620\n",
      "10635\n",
      "10650\n",
      "10665\n"
     ]
    }
   ],
   "source": [
    "# embarray = get_model_features(df, 15, encodings, model, embarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save(\"cola-bert-embs.npy\",embarray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get baseline, local & global representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = getWords(embarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BASELINE\r\n",
    "baseline_sentence_rep = embarray.reshape((-1,768*64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLOBAL METHOD\r\n",
    "# global_representations = global_method(np.asarray(words), n_pc_global, emb_len)\r\n",
    "# global_sentence_rep = flatten_pooling(global_representations, embarray)\r\n",
    "global_sentence_rep = np.load(\"global_sent_cola.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save(\"global_sent_cola.npy\",global_sentence_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOCAL METHOD\r\n",
    "isotropic_representations = cluster_based(np.asarray(words), n_cluster, n_pc, emb_len)\r\n",
    "sentence_rep = flatten_pooling(isotropic_representations, embarray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.asarray((df[\"label\"]).to_list())\r\n",
    "Y_tr = Y[:train_stop_ix]\r\n",
    "Y_dev = Y[train_stop_ix:dev_stop_ix]\r\n",
    "Y_te = Y[dev_stop_ix:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "reps_base = np.asarray(baseline_sentence_rep)\r\n",
    "X_tr = reps_base[:train_stop_ix]\r\n",
    "X_dev = reps_base[train_stop_ix:dev_stop_ix]\r\n",
    "X_te = reps_base[dev_stop_ix:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Beni\\anaconda3\\envs\\repro\\lib\\site-packages\\sklearn\\metrics\\_classification.py:873: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, score: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Beni\\anaconda3\\envs\\repro\\lib\\site-packages\\sklearn\\metrics\\_classification.py:873: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, score: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Beni\\anaconda3\\envs\\repro\\lib\\site-packages\\sklearn\\metrics\\_classification.py:873: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3, score: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Beni\\anaconda3\\envs\\repro\\lib\\site-packages\\sklearn\\metrics\\_classification.py:873: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4, score: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Beni\\anaconda3\\envs\\repro\\lib\\site-packages\\sklearn\\metrics\\_classification.py:873: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5, score: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Beni\\anaconda3\\envs\\repro\\lib\\site-packages\\sklearn\\metrics\\_classification.py:873: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6, score: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Beni\\anaconda3\\envs\\repro\\lib\\site-packages\\sklearn\\metrics\\_classification.py:873: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7, score: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Beni\\anaconda3\\envs\\repro\\lib\\site-packages\\sklearn\\metrics\\_classification.py:873: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8, score: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Beni\\anaconda3\\envs\\repro\\lib\\site-packages\\sklearn\\metrics\\_classification.py:873: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9, score: 0.0\n",
      "epoch 10, score: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Beni\\anaconda3\\envs\\repro\\lib\\site-packages\\sklearn\\metrics\\_classification.py:873: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    }
   ],
   "source": [
    "# Might get warnings as the baseline does not learn to predict any 0s\r\n",
    "clf1, score1 = get_best_classifier(10,X_tr,Y_tr,X_dev,Y_dev, scorer=\"matthew\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "reps_global = np.asarray(global_sentence_rep)\r\n",
    "X_tr = reps_global[:train_stop_ix]\r\n",
    "X_dev = reps_global[train_stop_ix:dev_stop_ix]\r\n",
    "X_te = reps_global[dev_stop_ix:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, score: 0.37013254584947247\n",
      "epoch 2, score: 0.4304667313379628\n",
      "epoch 3, score: 0.4659816741871816\n",
      "epoch 4, score: 0.4297676508136882\n",
      "epoch 5, score: 0.47273610719301584\n",
      "epoch 6, score: 0.4411903546350633\n",
      "epoch 7, score: 0.4147456011736498\n",
      "epoch 8, score: 0.4287204670167934\n",
      "epoch 9, score: 0.4735050808072697\n",
      "epoch 10, score: 0.44204253274357935\n"
     ]
    }
   ],
   "source": [
    "clf2, score2 = get_best_classifier(10,X_tr,Y_tr,X_dev,Y_dev, scorer=\"matthew\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "reps_local = np.asarray(sentence_rep)\r\n",
    "X_tr = reps_local[:train_stop_ix]\r\n",
    "X_dev = reps_local[train_stop_ix:dev_stop_ix]\r\n",
    "X_te = reps_local[dev_stop_ix:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, score: 0.34822354985655257\n",
      "epoch 2, score: 0.42798502066185135\n",
      "epoch 3, score: 0.39651592378586736\n",
      "epoch 4, score: 0.42294874068517124\n",
      "epoch 5, score: 0.4186898423718698\n",
      "epoch 6, score: 0.41932980960936644\n",
      "epoch 7, score: 0.4172194430405653\n",
      "epoch 8, score: 0.4346077035289075\n",
      "epoch 9, score: 0.43153554161096935\n",
      "epoch 10, score: 0.4221833158823561\n"
     ]
    }
   ],
   "source": [
    "clf3, score3 = get_best_classifier(10,X_tr,Y_tr,X_dev,Y_dev, scorer=\"matthew\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get test set predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "['clf3_cola.joblib']"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(clf1, \"clf1_cola.joblib\")\r\n",
    "dump(clf2, \"clf2_cola.joblib\")\r\n",
    "dump(clf3, \"clf3_cola.joblib\")\r\n",
    "# clf1 = load(\"clf1_cola.joblib\")\r\n",
    "# clf2 = load(\"clf2_cola.joblib\")\r\n",
    "# clf3 = load(\"clf3_cola.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft = ds[\"test\"].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_baseline = clf1.predict(baseline_sentence_rep[dev_stop_ix:])\r\n",
    "preds_global = clf2.predict(global_sentence_rep[dev_stop_ix:])\r\n",
    "preds_local = clf3.predict(sentence_rep[dev_stop_ix:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft[\"index\"] = dft[\"idx\"]\r\n",
    "dft[\"prediction\"] = preds_local\r\n",
    "dft[[\"index\",\"prediction\"]].to_csv(\"CoLA_local.tsv\", index=False, sep=\"\\t\")\r\n",
    "dft[\"prediction\"] = preds_global\r\n",
    "dft[[\"index\",\"prediction\"]].to_csv(\"CoLA_global.tsv\", index=False, sep=\"\\t\")\r\n",
    "dft[\"prediction\"] = preds_baseline\r\n",
    "dft[[\"index\",\"prediction\"]].to_csv(\"CoLA_baseline.tsv\", index=False, sep=\"\\t\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('repro': conda)",
   "name": "python3811jvsc74a57bd0556d0f6bb3e19b5350a50c9b037347830b2ef0c6b7dbb2b89c6068584bda62c6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}