{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\r\n",
    "from functions import *\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "from transformers import *\r\n",
    "import tensorflow as tf\r\n",
    "import pickle\r\n",
    "import scipy as sc\r\n",
    "import math as mt\r\n",
    "# from scipy import cluster as clst\r\n",
    "# from sklearn.metrics.pairwise import cosine_similarity\r\n",
    "# from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_dev = pd.read_csv('sts-dev.csv', delimiter='\\t' , error_bad_lines=False)\r\n",
    "df_dev = pd.read_csv('sts-test.csv', delimiter='\\t' , error_bad_lines=False)\r\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for errors\r\n",
    "# df_dev[pd.isna(df_dev[\"sentence2\"])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT\r\n",
    "casing = \"bert-base-uncased\" \r\n",
    "tokenizer = BertTokenizer.from_pretrained(casing, do_lower_case=True, add_special_tokens=True)\r\n",
    "\r\n",
    "config = BertConfig(hidden_dropout_prob=0.2, attention_probs_dropout_prob=0.2 )\r\n",
    "config.output_hidden_states = True\r\n",
    "\r\n",
    "model = TFBertModel.from_pretrained(casing, config = config)\r\n",
    "model.trainable = False\r\n",
    "\r\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get sentences and words representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get sentence representations BERT\r\n",
    "# sentences = get_representations(df_dev, tokenizer, model, 768)\r\n",
    "# sentences = np.load(\"bert-stsb-dev.npy\", allow_pickle=True).tolist()\r\n",
    "sentences = get_representations(df_dev, tokenizer, model, 768)\r\n",
    "words = getWords(sentences)\r\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HELPER\r\n",
    "np.save(\"bert-stsb-test.npy\", np.asarray(sentences, dtype=object))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get representations via baseline, global method, local (isotropy enhancing) method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cluster = 27 # Number of clusters to use\r\n",
    "n_pc = 12 # Number of main principal components to drop for local method\r\n",
    "n_pc_global = 15 # Number of main principal components to drop for global method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BASELINE\r\n",
    "baseline_sentence_rep = mean_pooling(words, sentences)\r\n",
    "baseline_score = similarity(baseline_sentence_rep, 768)\r\n",
    "\r\n",
    "# GLOBAL METHOD\r\n",
    "global_representations = global_method(np.asarray(words), n_pc_global, 768)\r\n",
    "global_sentence_rep = mean_pooling(global_representations, sentences)\r\n",
    "global_score = similarity(global_sentence_rep, 768)\r\n",
    "\r\n",
    "# LOCAL METHOD\r\n",
    "isotropic_representations = cluster_based(np.asarray(words), n_cluster, n_pc, 768)\r\n",
    "# calculating sentence representations based on mean word (isotropised) representations\r\n",
    "sentence_rep = mean_pooling(isotropic_representations, sentences)\r\n",
    "local_score = similarity(sentence_rep, 768)\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman Correlation baseline:  48.11715446651223\n",
      "Spearman Correlation global:  64.38035591129334\n",
      "Spearman Correlation local:  68.58722123795884\n",
      "Isotropy baseline:  0.00011038668\n",
      "Isotropy global:  0.5206524086147497\n",
      "Isotropy local:  0.7618754996633805\n"
     ]
    }
   ],
   "source": [
    "# performance\r\n",
    "print(\"Spearman Correlation baseline: \",sper_corrcoef(df_dev['corr'], baseline_score))\r\n",
    "print(\"Spearman Correlation global: \",sper_corrcoef(df_dev['corr'], global_score))\r\n",
    "print(\"Spearman Correlation local: \",sper_corrcoef(df_dev['corr'], local_score))\r\n",
    "\r\n",
    "# isotropy of space\r\n",
    "print(\"Isotropy baseline: \", isotropy(baseline_sentence_rep))\r\n",
    "print(\"Isotropy global: \", isotropy(global_representations))\r\n",
    "print(\"Isotropy local: \", isotropy(isotropic_representations))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('repro': conda)",
   "name": "python3811jvsc74a57bd0556d0f6bb3e19b5350a50c9b037347830b2ef0c6b7dbb2b89c6068584bda62c6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}